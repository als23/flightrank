{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load airports of each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L=json.loads(file('../json/L.json','r').read())\n",
    "M=json.loads(file('../json/M.json','r').read())\n",
    "N=json.loads(file('../json/N.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AP={}\n",
    "for c in M:\n",
    "    if c not in AP:AP[c]={}\n",
    "    for i in range(len(L[c])):\n",
    "        AP[c][N[c][i]]=L[c][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "record schedules for 2 weeks, then augment count with weekly flight numbers.\n",
    "seasonal and seasonal charter will count as once per week for 3 months, so 12/52 per week. TGM separate, since its history is in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse Departures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseurl='https://www.airportia.com/'\n",
    "import requests, urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def urlgetter(url):\n",
    "    s = requests.Session()\n",
    "    cookiesopen = s.get(url)\n",
    "    cookies=str(s.cookies)\n",
    "    fcookies=[[k[:k.find('=')],k[k.find('=')+1:k.find(' for ')]] for k in cookies[cookies.find('Cookie '):].split('Cookie ')[1:]]\n",
    "    #push token\n",
    "    opener = urllib2.build_opener()\n",
    "    for k in fcookies:\n",
    "        opener.addheaders.append(('Cookie', k[0]+'='+k[1]))\n",
    "    #read html\n",
    "    return s.get(url).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SD={}\n",
    "SC=json.loads(file('../json/SC2.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Canada\n",
      "YUY YUX --W- 8 --W- 15 YUL XBE --W- 9 --W- 16 YUB YUD YRT YUT"
     ]
    }
   ],
   "source": [
    "#pop out last - if applicable\n",
    "try: SD.pop(c)\n",
    "except: pass\n",
    "for h in range(len(AP.keys())):\n",
    "    c=AP.keys()[h]\n",
    "    #country not parsed yet\n",
    "    if c in SC:\n",
    "        if c not in SD:\n",
    "            SD[c]=[]\n",
    "            print h,c\n",
    "            airportialinks=AP[c]\n",
    "            sch={}\n",
    "            #all airports of country, where there is traffic\n",
    "            for i in airportialinks:\n",
    "                if i in SC[c]:\n",
    "                    print i,\n",
    "                    if i not in sch:sch[i]={}\n",
    "                    url=baseurl+airportialinks[i]\n",
    "                    m=urlgetter(url)\n",
    "                    for d in range (3,17):\n",
    "                        #date not parsed yet\n",
    "                        if d not in sch[i]:\n",
    "                            url=baseurl+airportialinks[i]+'departures/201704'+str(d)\n",
    "                            m=urlgetter(url)\n",
    "                            soup = BeautifulSoup(m, \"lxml\")\n",
    "                            #if there are flights at all\n",
    "                            if len(soup.findAll('table'))>0:\n",
    "                                sch[i][d]=pd.read_html(m)[0] \n",
    "                            else: print '--W-',d,\n",
    "            SD[c]=sch\n",
    "            print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbpath='E:/Dropbox/Public/datarepo/aviation/' #large file db path\n",
    "file(dbpath+\"json/SD_dest.json\",'w').write(repr(SD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnc_path='../../universal/countries/'\n",
    "cnc=pd.read_excel(cnc_path+'cnc.xlsx').set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MDF=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada Libyan Arab Jamahiriya Guernsey Turkmenistan Lithuania FYR of Macedonia Cambodia Dem. Rep. of Congo Ethiopia Aruba Argentina Bolivia Cameroon Burkina Faso Ghana Saudi Arabia Cape Verde Slovenia Guatemala Bosnia and Herzegovina Guinea Russian Federation Germany Dominica Liberia Maldives Paraguay Pakistan Oman Tanzania Greenland Gabon Niue Monaco New Zealand Yemen Jersey Jamaica Albania Samoa United Arab Emirates Uruguay India Azerbaijan Madagascar Lesotho Saint Vincent and the Grenadines Kenya Tajikistan Turkey Afghanistan Fiji Bangladesh Eritrea Solomon Islands Saint Lucia Mongolia France Syrian Arab Republic Bermuda Slovakia Somalia Peru Vanuatu Nauru Norway Malawi Cook Islands Benin Cuba Montenegro Saint Kitts and Nevis Togo China Armenia Antigua and Barbuda Dominican Republic Ukraine Bahrain Tonga Finland Western Sahara Indonesia Mauritius Sweden Vietnam British Virgin Islands Guyana Mali Bulgaria United States Romania Angola Cayman Islands South Africa Cyprus Brunei Darussalam Malaysia Austria Mozambique Uganda Hungary Niger Isle of Man Brazil Kuwait Panama Rep. of Moldova Costa Rica Luxembourg Bahamas Gibraltar Ireland Italy Nigeria Ecuador Czech Republic Australia Iran Algeria El Salvador Tuvalu Marshall Islands Chile Puerto Rico Belgium Kiribati Haiti Belize Hong Kong Sierra Leone Georgia Gambia Philippines Portugal Morocco Namibia Guinea-Bissau Thailand Switzerland Grenada Seychelles Chad Estonia Kosovo Equatorial Guinea Lebanon Uzbekistan Egypt Djibouti Rwanda Timor-Leste Spain Colombia Burundi Taiwan Turks and Caicos Islands Barbados Qatar Palau Bhutan Sudan Nepal São Tomé and Principe Malta Netherlands Suriname Anguilla Venezuela Micronesia (Federated States of) Israel Myanmar (Burma) Iceland Zambia Senegal Papua New Guinea Cote d'Ivoire Lao People's Dem. Rep. Zimbabwe Jordan Denmark Kazakhstan Poland Cent African Rep Mauritania Kyrgyzstan Iraq Montserrat Trinidad and Tobago Latvia People's Republic of Korea South Sudan Japan Croatia Belarus Honduras Mexico Tunisia Nicaragua Singapore Serbia Comoros United Kingdom Congo Greece Sri Lanka French Guiana Rep. of Korea Botswana\n"
     ]
    }
   ],
   "source": [
    "for c in SD:\n",
    "    sch=SD[c]\n",
    "    mdf=pd.DataFrame()\n",
    "    for i in sch:\n",
    "        for d in sch[i]:\n",
    "            df=sch[i][d].drop(sch[i][d].columns[3:],axis=1).drop(sch[i][d].columns[0],axis=1)\n",
    "            df['From']=i\n",
    "            df['Date']=d\n",
    "            mdf=pd.concat([mdf,df])\n",
    "    mdf=mdf.replace('Hahn','Frankfurt')\n",
    "    mdf=mdf.replace('Hahn HHN','Frankfurt HHN')\n",
    "    if len(sch)>0:\n",
    "        mdf['City']=[i[:i.rfind(' ')] for i in mdf['To']]\n",
    "        mdf['Airport']=[i[i.rfind(' ')+1:] for i in mdf['To']]\n",
    "        cpath=str(cnc.T.loc[c]['ISO2']).lower()\n",
    "        if cpath=='nan':cpath='na'\n",
    "        file('../countries/'+cpath+\"/json/mdf_dest.json\",'w').write(json.dumps(mdf.reset_index().to_json()))\n",
    "        MDF=pd.concat([MDF,mdf])\n",
    "        print c,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbpath='E:/Dropbox/Public/datarepo/aviation/' #large file db path\n",
    "MDF.reset_index().to_json(dbpath+'json/MDF_dest.json')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
