{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SC=json.loads(file('../json/SC2.json','r').read())\n",
    "I3=json.loads(file('../json/I3.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada Turkmenistan Saint Helena Lithuania Cambodia Ethiopia Aruba Perú Argentina Bolivia Cameroon Burkina Faso Ghana Saudi Arabia Cape Verde United States Minor Outlying Islands Cocos (Keeling) Islands Slovenia Guatemala Guinea Wallis And Futuna Dominica Liberia Maldives Pakistan Oman Tanzania Saint Kitts And Nevis Albania Gabon Saint Pierre and Miquelon Monaco New Zealand Yemen Denmark Jamaica Greenland Samoa United Arab Emirates Guam Kosovo India Azerbaijan Madagascar Lesotho Saint Vincent and the Grenadines Kenya South Korea Belarus Tajikistan Turkey Afghanistan Northern Mariana Islands Eritrea Solomon Islands Saint Lucia Mongolia France Bermuda Slovakia Somalia Laos Nauru Norway Malawi Cook Islands Benin Libya Cuba Montenegro Djibouti Togo China Armenia Dominican Republic Germany Ukraine Bahrain Tonga Cayman Islands Western Sahara Finland Central African Republic Mauritius Sweden Vietnam Antigua And Barbuda Macedonia Mali Russia Bulgaria United States Romania Angola Chad South Africa Cyprus Caribbean Netherlands Malaysia Austria Mozambique Uganda Hungary Niger Brazil Faroe Islands Kuwait Panama Guyana Costa Rica Luxembourg American Samoa Bahamas British Virgin Islands Gibraltar Ireland Italy Nigeria Ecuador Bangladesh Brunei Australia Iran Algeria El Salvador Tuvalu Czech Republic Marshall Islands Chile Puerto Rico Belgium Kiribati Haiti Belize Hong Kong Sierra Leone Georgia Gambia Philippines Moldova French Guiana Morocco Namibia French Polynesia Guinea-Bissau Thailand Switzerland Grenada Cote D'ivoire (Ivory Coast) U.S. Virgin Islands Seychelles Portugal Estonia Uruguay Equatorial Guinea Lebanon Uzbekistan Egypt Falkland Islands (Malvinas) Rwanda Timor-Leste Spain Colombia Reunion Burundi Taiwan Turks and Caicos Islands Barbados Qatar Palau Curacao Bhutan Sudan Nepal São Tomé and Principe Micronesia Netherlands Bosnia And Herzegovina Suriname Anguilla Venezuela Israel Indonesia Iceland Zambia Senegal Papua New Guinea Zimbabwe Jordan Vanuatu Martinique Kazakhstan Poland Mauritania Kyrgyzstan Mayotte Iraq Montserrat New Caledonia North Korea Paraguay Latvia South Sudan Japan Croatia Syria Guadeloupe Burma Honduras Malta Mexico Tunisia Nicaragua Singapore Serbia Comoros United Kingdom Trinidad And Tobago Congo Greece Sri Lanka Fiji Botswana\n"
     ]
    }
   ],
   "source": [
    "for c in SC:\n",
    "    if len(SC[c])>0:\n",
    "\n",
    "        print c,\n",
    "        #read mdf data\n",
    "        cpath=I3[c].lower()\n",
    "        cpath='../countries/'+cpath\n",
    "        mdf_dest=pd.read_json(json.loads(file(cpath+'/json/mdf_dest.json','r').read()))\n",
    "        mdf_arrv=pd.read_json(json.loads(file(cpath+'/json/mdf_arrv.json','r').read()))\n",
    "        mdf_dest['ID']=mdf_dest['From']\n",
    "        mdf_arrv['ID']=mdf_arrv['To']\n",
    "        mdf=pd.concat([mdf_dest,mdf_arrv])\n",
    "\n",
    "        #save combined - not necessary, space hog\n",
    "        #file(cpath+\"/json/mdf.json\",'w').write(json.dumps(mdf.reset_index().to_json()))\n",
    "\n",
    "        #parse data into flights\n",
    "        mdg=mdf.set_index(['ID','City','Airport','Airline'])\n",
    "        flights={}\n",
    "        minn=1.0 #want to see minimum 1 flight in the past 2 weeks\n",
    "        for i in mdg.index.get_level_values(0).unique():\n",
    "            #2 weeks downloaded. want to get weekly freq. but multi by 2 dept+arrv\n",
    "            d=4.0\n",
    "            if i not in flights:flights[i]={}\n",
    "            for j in mdg.loc[i].index.get_level_values(0).unique():\n",
    "                if len(mdg.loc[i].loc[j])>minn: #minimum 1 flights required in this period at least once every 2 weeks\n",
    "                    if j not in flights[i]:flights[i][j]={'airports':{},'7freq':0}\n",
    "                    flights[i][j]['7freq']=len(mdg.loc[i].loc[j])/d \n",
    "                    for k in mdg.loc[i].loc[j].index.get_level_values(0).unique():\n",
    "                        if len(mdg.loc[i].loc[j].loc[k])>minn:\n",
    "                            if k not in flights[i][j]['airports']:flights[i][j]['airports'][k]={'airlines':{},'7freq':0}\n",
    "                            flights[i][j]['airports'][k]['7freq']=len(mdg.loc[i].loc[j].loc[k])/d\n",
    "                            for l in mdg.loc[i].loc[j].loc[k].index.get_level_values(0).unique():\n",
    "                                try:\n",
    "                                    if len(mdg.loc[i].loc[j].loc[k].loc[l])>minn: \n",
    "                                        if l not in flights[i][j]['airports'][k]['airlines']:flights[i][j]['airports'][k]['airlines'][l]={'7freq':0}\n",
    "                                        flights[i][j]['airports'][k]['airlines'][l]['7freq']=len(mdg.loc[i].loc[j].loc[k].loc[l])/d\n",
    "                                except:pass\n",
    "        file(cpath+\"/json/flights.json\",'w').write(json.dumps(flights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbpath='E:/Dropbox/Public/datarepo/aviation/' #large file db path\n",
    "MDF_dest=json.loads(file(dbpath+'json/MDF_dest.json','r').read())\n",
    "MDF_arrv=json.loads(file(dbpath+'json/MDF_arrv.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdf_dest=pd.DataFrame(MDF_dest)\n",
    "gdf_arrv=pd.DataFrame(MDF_arrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf_dest['ID']=gdf_dest['From']\n",
    "gdf_arrv['ID']=gdf_arrv['To']\n",
    "gdf=pd.concat([gdf_dest,gdf_arrv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parse data into flights\n",
    "mdg=gdf.set_index(['ID','City','Airport','Airline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "directory='../countries/wd'\n",
    "if not os.path.exists(directory) :\n",
    "    os.makedirs(directory)\n",
    "for j in ['code','d3','json','map']:\n",
    "    if not os.path.exists(directory+'/'+j):\n",
    "        os.makedirs(directory+'/'+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flights={}\n",
    "minn=1.0 #want to see minimum 1 flight in the past 2 weeks\n",
    "for i in mdg.index.get_level_values(0).unique():\n",
    "    #2 weeks downloaded. want to get weekly freq. but multi by 2 dept+arrv\n",
    "    d=4.0\n",
    "    if i not in flights:flights[i]={}\n",
    "    for j in mdg.loc[i].index.get_level_values(0).unique():\n",
    "        if len(mdg.loc[i].loc[j])>minn: #minimum 1 flights required in this period at least once every 2 weeks\n",
    "            if j not in flights[i]:flights[i][j]={'airports':{},'7freq':0}\n",
    "            flights[i][j]['7freq']=len(mdg.loc[i].loc[j])/d \n",
    "            for k in mdg.loc[i].loc[j].index.get_level_values(0).unique():\n",
    "                if len(mdg.loc[i].loc[j].loc[k])>minn:\n",
    "                    if k not in flights[i][j]['airports']:flights[i][j]['airports'][k]={'airlines':{},'7freq':0}\n",
    "                    flights[i][j]['airports'][k]['7freq']=len(mdg.loc[i].loc[j].loc[k])/d\n",
    "                    for l in mdg.loc[i].loc[j].loc[k].index.get_level_values(0).unique():\n",
    "                        try:\n",
    "                            if len(mdg.loc[i].loc[j].loc[k].loc[l])>minn: \n",
    "                                if l not in flights[i][j]['airports'][k]['airlines']:flights[i][j]['airports'][k]['airlines'][l]={'7freq':0}\n",
    "                                flights[i][j]['airports'][k]['airlines'][l]['7freq']=len(mdg.loc[i].loc[j].loc[k].loc[l])/d\n",
    "                        except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file(\"../countries/wd/json/flights.json\",'w').write(json.dumps(flights))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
